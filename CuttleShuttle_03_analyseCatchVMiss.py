# -*- coding: utf-8 -*-
"""
Paper: "An experimental method for evoking and characterizing dynamic color patterning of cuttlefish during prey capture" by Danbee Kim, Kendra Buresch, Roger Hanlon, and Adam R. Kampff
Analysis: Step 2 of process_cuttle_python Python Workflow.
WARNING: This script takes a few hours to run shuffle tests (bootstrapped statistical test).

Loads intermediate files generated by CuttleShuttle_01_ProcessCuttlePython_genBandEnergies.py and/or by CuttleShuttle_01_CannyEdgeDetector.bonsai.
Baselines and normalises individual trials in order to pool trials across all animals. Categorizes trials by catch versus miss.
Makes a shuffle test of the successful versus unsuccessful tentacle shots and plots the result.

Optional flags:
"--units": 'percent_change' (default) or 'zscore'
"--baseline": 60 (default) or any integer value from 1-179
"--plotZScore": False (default) or True
"--plotRandomTraces": False (default) or True
"--plotShuffles": False (default) or True
"--plotBaselineHist": False (default) or True
"--plot_labels": False (default) or True

@author: Danbee Kim and Adam R Kampff
"""
import os
import glob
import numpy as np
import scipy
import scipy.signal
import matplotlib.pyplot as plt
import cv2
import datetime
import logging
import pdb
import argparse

###################################
# SET CURRENT WORKING DIRECTORY
###################################
cwd = os.getcwd()
###################################
# SCRIPT LOGGER
###################################
# grab today's date
now = datetime.datetime.now()
today_dateTime = now.strftime("%Y-%m-%d_%H-%M-%S")
logging.basicConfig(filename="process_cuttle_python_03_" + today_dateTime + ".log", filemode='w', level=logging.INFO)
###################################
# FUNCTIONS
###################################

##########################################################
#### MODIFY THIS FIRST FUNCTION BASED ON THE LOCATIONS OF:
# 1) data_folder (parent folder with all intermediate data)
# AND
# 2) plots_folder (parent folder for all plots output from analysis scripts)
### Current default uses a debugging source dataset
##########################################################
def load_data():
    data_dir_percentChange = r'C:\Users\taunsquared\Dropbox\CuttleShuttle\analysis\WoodsHoleAnalysis\data'
    data_dir_canny = r'C:\Users\taunsquared\Documents\GitHub\CuttleShuttle-Analysis\Workflows\CannyCount_20191025'
    plots_dir = r'C:\Users\taunsquared\Dropbox\CuttleShuttle\analysis\WoodsHoleAnalysis\draftPlots'
    return data_dir_percentChange, data_dir_canny, plots_dir
##########################################################

def categorize_by_animal(TGB_files, unit_type):
    all_animals_dict = {}
    if unit_type == 'percent_change':
        # collect all power-at-freq and categorize by animal and type (catch vs miss)
        for TGB_file in TGB_files: 
            TGB_name = os.path.basename(TGB_file)
            TGB_animal = TGB_name.split("_")[1]
            TGB_type = TGB_name.split("_")[4]
            TS_bandEnergies = np.load(TGB_file)
            # extract power at each frequency band for every frame
            all_bands = range(TS_bandEnergies.shape[1])
            power_at_each_frequency = {key:[] for key in all_bands}
            for frame in TS_bandEnergies:
                for band in frame:
                    i, = np.where(frame == band)[0]
                    power_at_each_frequency[i].append(band)
            all_animals_dict.setdefault(TGB_animal,[]).append(power_at_each_frequency)
    if unit_type == 'zscore':
        # collect all canny counts and categorize by animal and type (catch vs miss)
        for TGB_file in TGB_files: 
            TGB_name = TGB_file.split(os.sep)[-1]
            TGB_animal = TGB_name.split("_")[1]
            TGB_type = TGB_name.split("_")[4]
            TGB_moment = np.genfromtxt(TGB_file, dtype=np.float, delimiter=",")
            all_animals_dict.setdefault(TGB_animal,[]).append(TGB_moment)
    return all_animals_dict

def categorize_by_animal_catchVmiss(TGB_files, unit_type):
    catch_dict = {}
    miss_dict = {}
    if unit_type == 'percent_change':
        # collect all canny counts and categorize by animal and type (catch vs miss)
        for TGB_file in TGB_files: 
            TGB_name = os.path.basename(TGB_file)
            TGB_animal = TGB_name.split("_")[1]
            TGB_type = TGB_name.split("_")[4]
            TS_bandEnergies = np.load(TGB_file)
            # extract power at each frequency band for every frame
            all_bands = range(TS_bandEnergies.shape[1])
            power_at_each_frequency = {key:[] for key in all_bands}
            for frame in TS_bandEnergies:
                for band in frame:
                    i, = np.where(frame == band)[0]
                    power_at_each_frequency[i].append(band)
            if TGB_type == "catch":
                catch_dict.setdefault(TGB_animal,[]).append(power_at_each_frequency)
            if TGB_type == "miss": 
                miss_dict.setdefault(TGB_animal,[]).append(power_at_each_frequency)
    if unit_type == 'zscore':
        # collect all canny counts and categorize by animal and type (catch vs miss)
        for TGB_file in TGB_files: 
            TGB_name = TGB_file.split(os.sep)[-1]
            TGB_animal = TGB_name.split("_")[1]
            TGB_type = TGB_name.split("_")[4]
            TGB_moment = np.genfromtxt(TGB_file, dtype=np.float, delimiter=",")
            if TGB_type == "catch":
                catch_dict.setdefault(TGB_animal,[]).append(TGB_moment)
            if TGB_type == "miss": 
                miss_dict.setdefault(TGB_animal,[]).append(TGB_moment)
    return catch_dict, miss_dict

def filtered_basesub_count(TS_dict, prey_type, baseline_len, savgol_filter_window):
    basesub_filtered_TS = {}
    # make baseline for each animal, catch vs miss
    for animal in TS_dict: 
        basesub_filtered_TS[animal] = {}
        try:
            # baseline subtract each trial, then apply sav-gol filter
            all_filtered_basesub_trials = []
            for trial in TS_dict[animal]:
                filtered_trial = scipy.signal.savgol_filter(trial, savgol_filter_window, 3)
                baseline = np.nanmean(filtered_trial[0:baseline_len])
                filtered_basesub_trial = [float(x-baseline) for x in filtered_trial]
                all_filtered_basesub_trials.append(filtered_basesub_trial)
            basesub_filtered_mean_byTB = np.nanmean(all_filtered_basesub_trials, axis=0)
            basesub_filtered_mean_bySess = np.nanmean(all_filtered_basesub_trials)
            basesub_filtered_std_byTB = np.nanstd(all_filtered_basesub_trials, axis=0, ddof=1)
            basesub_filtered_std_bySess = np.nanstd(all_filtered_basesub_trials, ddof=1)
            basesub_filtered_TS[animal]['trials'] = all_filtered_basesub_trials
            basesub_filtered_TS[animal]['mean tb'] = basesub_filtered_mean_byTB
            basesub_filtered_TS[animal]['mean trial'] = basesub_filtered_mean_bySess
            basesub_filtered_TS[animal]['std tb'] = basesub_filtered_std_byTB
            basesub_filtered_TS[animal]['std trial'] = basesub_filtered_std_bySess
        except Exception:
            print("{a} made no tentacle shots during {p} prey movement type".format(a=animal, p=prey_type))
    return basesub_filtered_TS

def zScored_count(Zscore_type, dict_to_Zscore, dict_for_mean_std):
    zScored_dict = {}
    for animal in dict_to_Zscore:
        zScored_dict[animal] = []
        for trial in dict_to_Zscore[animal]['trials']:
            trial_array = np.array(trial)
            if Zscore_type=='timebin':
                trial_zscored = (trial_array - dict_for_mean_std[animal]['mean tb'])/dict_for_mean_std[animal]['std tb']
            if Zscore_type=='trial':
                trial_zscored = []
                for timebin in trial:
                    tb_zscored = (timebin - dict_for_mean_std[animal]['mean trial'])/dict_for_mean_std[animal]['std trial']
                    trial_zscored.append(tb_zscored)
            zScored_dict[animal].append(trial_zscored)
    return zScored_dict

def plot_indiv_animals(analysis_type_str, preprocess_str, metric_str, prey_type_str, allA_C_dict, allA_M_dict, TGB_bucket, baseline_len, plots_dir, todays_dt, plot_labels):
    # plot individual animals
    img_type = ['.png', '.pdf']
    for animal in allA_C_dict.keys(): 
        try:
            if 'Zscored' in preprocess_str:
                N_catch = len(allA_C_dict[animal])
                N_miss = len(allA_M_dict[animal])
                catches_mean = np.nanmean(allA_C_dict[animal], axis=0)
                misses_mean = np.nanmean(allA_M_dict[animal], axis=0)
                # set fig path and title
                if len(prey_type_str.split(' '))>1:
                    figure_name = analysis_type_str +'_'+ preprocess_str +'_'+ prey_type_str.split(' ')[1] + 'Trials_' + animal + "_" + todays_dt + img_type[0]
                else:
                    figure_name = analysis_type_str +'_'+ preprocess_str +'_'+ prey_type_str + 'Trials_' + animal + "_" + todays_dt + img_type[0]
                figure_path = os.path.join(plots_dir, figure_name)
                figure_title = 'Z-scored mean change from baseline of {m} in ROI on cuttlefish mantle during tentacle shots, as detected by {at}\n Individual trials plotted with more transparent traces \n Baseline: mean of {m} from t=0 to t={b} seconds \n Prey Movement type: {p}, Animal: {a}\n Number of catches: {Nc}, Number of misses: {Nm}'.format(m=metric_str, at=analysis_type_str, b=str(baseline_len/60), p=prey_type_str, a=animal, Nc=str(N_catch), Nm=str(N_miss))
                # setup fig
                plt.figure(figsize=(16,9), dpi=200)
                plt.suptitle(figure_title, fontsize=12, y=0.99)
                plt.ylabel("Change from baseline in number of edges")
                plot_xticks = np.arange(0, len(allA_C_dict[animal][0]), step=60)
                plt.xticks(plot_xticks, ['%.1f'%(x/60) for x in plot_xticks])
                #plt.xlim(0,180)
                plt.ylim(-6, 6)
                plt.xlabel("Seconds")
                plt.grid(b=True, which='major', linestyle='-')
                # plot z-scored edge counts
                for trial in allA_M_dict[animal]:
                    plt.plot(trial, linewidth=1, color=[1.0, 0.0, 0.0, 0.1])
                for trial in allA_C_dict[animal]:
                    plt.plot(trial, linewidth=1, color=[0.0, 0.0, 1.0, 0.1])
                plt.plot(misses_mean.T, linewidth=2, color=[1.0, 0.0, 0.0, 0.8], label='Miss')
                #plt.fill_between(range(len(allA_M_dict_mean[animal])), misses_mean-canny_std_miss, misses_mean+canny_std_miss, color=[1.0, 0.0, 0.0, 0.1])
                plt.plot(catches_mean.T, linewidth=2, color=[0.0, 0.0, 1.0, 0.8], label='Catch')
                #plt.fill_between(range(len(allA_C_dict_mean[animal])), catches_mean-canny_std_catch, catches_mean+canny_std_catch, color=[0.0, 0.0, 1.0, 0.1])
                # plot events
                ymin, ymax = plt.ylim()
                plt.plot((baseline_len, baseline_len), (ymin, ymax), 'm--', linewidth=1)
                plt.plot((TGB_bucket, TGB_bucket), (ymin, ymax), 'g--', linewidth=1)
                if plot_labels:
                    plt.text(baseline_len, ymax-0.8, "End of \nbaseline period", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor='magenta', boxstyle='round,pad=0.35'))
                    plt.text(TGB_bucket, ymax-0.5, "Tentacles Go Ballistic\n(TGB)", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor='green', boxstyle='round,pad=0.35'))
                    plt.legend(loc='upper left')
                # save fig
                plt.savefig(figure_path)
                plt.show(block=False)
                plt.pause(1)
                plt.close()
            else:
                if animal in allA_C_dict:
                    N_catch = len(allA_C_dict[animal]['trials'])
                    catches_mean = np.nanmean(allA_C_dict[animal]['trials'], axis=0)
                if animal in allA_M_dict:
                    N_miss = len(allA_M_dict[animal]['trials'])
                    misses_mean = np.nanmean(allA_M_dict[animal]['trials'], axis=0)
                # set fig path and title
                figure_name = analysis_type_str +'_'+ preprocess_str +'_'+ prey_type_str.split(' ')[1] + 'Trials_' + animal + "_" + todays_dt + img_type[0]
                figure_path = os.path.join(plots_dir, figure_name)
                figure_title = 'SavGol filtered and baseline subtracted mean change from baseline of {m} in ROI on cuttlefish mantle during tentacle shots, as detected by {at}\n Individual trials plotted with more transparent traces \n Baseline: mean of {m} from t=0 to t={b} seconds \n Prey Movement type: {p}, Animal: {a}\n Number of catches: {Nc}, Number of misses: {Nm}'.format(m=metric_str, at=analysis_type_str, b=str(baseline_len/60), p=prey_type_str, a=animal, Nc=str(N_catch), Nm=str(N_miss))
                # setup fig
                plt.figure(figsize=(16,9), dpi=200)
                plt.suptitle(figure_title, fontsize=12, y=0.99)
                plt.ylabel("Change from baseline in number of edges")
                plot_xticks = np.arange(0, len(allA_C_dict[animal]['trials'][0]), step=60)
                plt.xticks(plot_xticks, ['%.1f'%(x/60) for x in plot_xticks])
                #plt.xlim(0,180)
                #plt.ylim(-6, 6)
                plt.xlabel("Seconds")
                plt.grid(b=True, which='major', linestyle='-')
                # plot z-scored edge counts
                if animal in allA_M_dict:
                    for trial in allA_M_dict[animal]['trials']:
                        plt.plot(trial, linewidth=1, color=[1.0, 0.0, 0.0, 0.1])
                if animal in allA_C_dict:
                    for trial in allA_C_dict[animal]['trials']:
                        plt.plot(trial, linewidth=1, color=[0.0, 0.0, 1.0, 0.1])
                if animal in allA_M_dict:
                    plt.plot(misses_mean.T, linewidth=2, color=[1.0, 0.0, 0.0, 0.8], label='Miss')
                if animal in allA_C_dict:
                    plt.plot(catches_mean.T, linewidth=2, color=[0.0, 0.0, 1.0, 0.8], label='Catch')
                # plot events
                ymin, ymax = plt.ylim()
                plt.plot((baseline_len, baseline_len), (ymin, ymax), 'm--', linewidth=1)
                plt.plot((TGB_bucket, TGB_bucket), (ymin, ymax), 'g--', linewidth=1)
                if plot_labels:
                    plt.text(baseline_len, ymax-ymax/10, "End of \nbaseline period", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor='magenta', boxstyle='round,pad=0.35'))
                    plt.text(TGB_bucket, ymax-ymax/20, "Tentacles Go Ballistic\n(TGB)", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor='green', boxstyle='round,pad=0.35'))
                    plt.legend(loc='upper left')
                # save fig
                plt.savefig(figure_path)
                plt.show(block=False)
                plt.pause(1)
                plt.close()
        except Exception:
            plt.close()
            print("{a} did not make any catches and/or misses during {p} prey movement".format(a=animal,p=prey_type_str))

def percent_change_from_baseline(TS_dict, prey_type, baseline_len):
    percentChange_TS = {}
    # make baseline for each animal, catch vs miss
    for animal in TS_dict: 
        percentChange_TS[animal] = {}
        try:
            # baseline subtract each frequency during each trial
            allFreq_allTrials_percentChange = {}
            for i,trial in enumerate(TS_dict[animal]):
                for freq_band in trial:
                    percentChange_TS[animal][freq_band] = {}
                    this_freq_baseline = np.nanmean(TS_dict[animal][i][freq_band][0:baseline_len])
                    this_freq_percentChange = [(float(x/this_freq_baseline)-1)*100 for x in TS_dict[animal][i][freq_band]]
                    allFreq_allTrials_percentChange.setdefault(freq_band,[]).append(this_freq_percentChange)
            for freq_band in allFreq_allTrials_percentChange:
                percentChange_TS[animal][freq_band] = allFreq_allTrials_percentChange[freq_band]
        except Exception:
            print("{a} made no tentacle shots during {p} prey movement type".format(a=animal, p=prey_type))
    return percentChange_TS

def plot_BaselineHistograms_perZScore(analysis_type_str, preprocess_str, metric_str, prey_type_str, observed_baseline_dict, zscore, baseline_len, todays_dt, plots_dir, plot_labels):
    # set fig path and title
    figure_name = analysis_type_str+'_'+preprocess_str+'_pooledAnimals_'+str(zscore)+'_baselineHistSanityCheck_'+todays_dt+'.png'
    figure_path = os.path.join(plots_dir, figure_name)
    figure_title = 'Histogram of baseline period of {m} in ROI on cuttlefish mantle during tentacle shots, as detected by {at}\n Zscore type: {zs} \n Baseline: mean of {m} from t=0 to t={b} second(s) for each trial \n Prey Movement type: {p}, pooled across all animals'.format(m=metric_str, at=analysis_type_str, zs=zscore, b=str(baseline_len/60), p=prey_type_str)
    # setup fig
    plt.figure(figsize=(16,9), dpi=200)
    plt.suptitle(figure_title, fontsize=12, y=0.99)
    plt.hist(observed_baseline_dict[zscore], bins=140, normed=True)
    # visual check to see if the distribution is gaussian
    mean_baseline = np.nanmean(observed_baseline_dict[zscore])
    std_baseline = np.nanstd(observed_baseline_dict[zscore])
    x = np.linspace(min(observed_baseline_dict[zscore]), max(observed_baseline_dict[zscore]), 100)
    f = np.exp(-(1/2)*np.power((x - mean_baseline)/std_baseline,2)) / (std_baseline*np.sqrt(2*np.pi))
    plt.plot(x,f, label='gaussian distribution')
    plt.legend()
    # save fig
    plt.savefig(figure_path)
    plt.show(block=False)
    plt.pause(1)
    plt.close()

def plot_BaselineHistograms_perFreqBand(analysis_type_str, preprocess_str, metric_str, prey_type_str, observed_baseline_dict, freq_band, baseline_len, todays_dt, plots_dir, plot_labels):
    # set fig path and title
    figure_name = analysis_type_str+'_'+preprocess_str+'_pooledAnimals_FreqBand'+str(freq_band)+'_baselineHistSanityCheck_'+todays_dt+'.png'
    figure_path = os.path.join(plots_dir, figure_name)
    figure_title = 'Histogram of baseline period of {m} in ROI on cuttlefish mantle during tentacle shots, as detected by {at}\n Frequency Band {fb} \n Baseline: mean of {m} from t=0 to t={b} second(s) for each trial \n Prey Movement type: {p}, pooled across all animals'.format(m=metric_str, at=analysis_type_str, fb=str(freq_band), b=str(baseline_len/60), p=prey_type_str)
    # setup fig
    plt.figure(figsize=(16,9), dpi=200)
    plt.suptitle(figure_title, fontsize=12, y=0.99)
    plt.hist(observed_baseline_dict[freq_band], bins=140, normed=True)
    # visual check to see if the distribution is gaussian
    mean_baseline = np.nanmean(observed_baseline_dict[freq_band])
    std_baseline = np.nanstd(observed_baseline_dict[freq_band])
    x = np.linspace(min(observed_baseline_dict[freq_band]), max(observed_baseline_dict[freq_band]), 100)
    f = np.exp(-(1/2)*np.power((x - mean_baseline)/std_baseline,2)) / (std_baseline*np.sqrt(2*np.pi))
    plt.plot(x,f, label='gaussian distribution')
    plt.legend()
    # save fig
    plt.savefig(figure_path)
    plt.show(block=False)
    plt.pause(1)
    plt.close()

def pool_acrossA_keepTemporalStructure_eachFreq(catches_dict, misses_dict, frame_start, frame_end, prey_type_str):
    pooled_catches = {}
    pooled_misses = {}
    pooled_catches_Ntrials = 0
    pooled_misses_Ntrials = 0
    for animal in catches_dict:
        thisA_catchesN = len(catches_dict[animal][0])
        pooled_catches_Ntrials = pooled_catches_Ntrials + thisA_catchesN
        thisA_missesN = len(misses_dict[animal][0])
        pooled_misses_Ntrials = pooled_misses_Ntrials + thisA_missesN
        for freq_band in catches_dict[animal]:
            if thisA_catchesN != 0:
                for trial in catches_dict[animal][freq_band]:
                    if frame_end == -1:
                        pooled_catches.setdefault(freq_band,[]).append(trial[frame_start:])
                    else:     
                        pooled_catches.setdefault(freq_band,[]).append(trial[frame_start:frame_end])
            else:
                print('{a} made no catch tentacle shots during {p} prey movement'.format(a=animal, p=prey_type_str))
            if thisA_missesN != 0:
                for trial in misses_dict[animal][freq_band]:
                    if frame_end == -1:
                        pooled_misses.setdefault(freq_band,[]).append(trial[frame_start:])
                    else:     
                        pooled_misses.setdefault(freq_band,[]).append(trial[frame_start:frame_end])
            else:
                print('{a} made no miss tentacle shots during {p} prey movement'.format(a=animal, p=prey_type_str))
    return pooled_catches, pooled_catches_Ntrials, pooled_misses, pooled_misses_Ntrials

def pool_acrossA_keepTemporalStructure(catches_dict, misses_dict, timebin_start, timebin_end, prey_type_str):
    pooled_catches = []
    pooled_catches_Ntrials = 0
    pooled_misses = []
    pooled_misses_Ntrials = 0
    for animal in catches_dict:
        thisA_catchesN = len(catches_dict[animal])
        pooled_catches_Ntrials = pooled_catches_Ntrials + thisA_catchesN
        if thisA_catchesN != 0:
            for trial in catches_dict[animal]:
                if timebin_end == -1:
                    pooled_catches.append(trial[timebin_start:])
                else:     
                    pooled_catches.append(trial[timebin_start:timebin_end])
        else:
            print('{a} made no catch tentacle shots during {p} prey movement'.format(a=animal, p=prey_type_str))
        thisA_missesN = len(misses_dict[animal])
        pooled_misses_Ntrials = pooled_misses_Ntrials + thisA_missesN
        if thisA_missesN != 0:
            for trial in misses_dict[animal]:
                if timebin_end == -1:
                    pooled_misses.append(trial[timebin_start:])
                else:     
                    pooled_misses.append(trial[timebin_start:timebin_end])
        else:
            print('{a} made no miss tentacle shots during {p} prey movement'.format(a=animal, p=prey_type_str))
    pooled_catches_array = np.array(pooled_catches)
    pooled_misses_array = np.array(pooled_misses)
    return pooled_catches_array, pooled_catches_Ntrials, pooled_misses_array, pooled_misses_Ntrials

def shuffle_test(Group1, Group2, N_Shuffles, Group1_str, Group2_str, Group1_N, Group2_N, plot_on, plots_dir, todays_dt):
    # Observed performance
    OPerf = np.nanmean(Group1) - np.nanmean(Group2)
    # Shuffle the dataset and compare means again
    num_of_shuffles = N_Shuffles
    SPerf = np.zeros((num_of_shuffles,1))
    All_Group = np.concatenate([Group1, Group2])
    for shuff in range(num_of_shuffles):
        shuff_response = np.random.permutation(All_Group)
        SPerf[shuff] = np.nanmean(shuff_response[0:len(Group1)]) - np.nanmean(shuff_response[len(Group1):])
    # p-value of shuffle test
    pVal = np.nanmean(SPerf**2 >= OPerf**2)
    # sigma
    shuffled_mean = np.nanmean(SPerf)
    sigma_shuff = np.nanstd(SPerf, ddof=1)
    shuff_975p = np.percentile(SPerf, 97.5)
    shuff_025p = np.percentile(SPerf, 2.5)
    if plot_on:
        # show histogram of diffs of shuffled means
        figure_name = 'ShuffleTest_'+ Group1_str + '_' + Group2_str + '_' + todays_dt + '.png'
        figure_path = os.path.join(plots_dir, figure_name)
        figure_title = "Histogram of the differences in means of randomly labeled data, Number of shuffles = {Ns}\n Group 1: {G1}, N = {G1N}\n Group 2: {G2}, N = {G2N}\n P-value of shuffle test: {p:.4f}, Mean of shuffle test: {m:.4f}, Sigma of shuffle test: {s:.4f}".format(Ns=N_Shuffles, G1=Group1_str, G1N=Group1_N, G2=Group2_str, G2N=Group2_N, p=pVal, m=shuffled_mean, s=sigma_shuff)
        plt.figure(figsize=(16,9), dpi=200)
        plt.suptitle(figure_title, fontsize=12, y=0.98)
        plt.hist(SPerf)
        ymin, ymax = plt.ylim()
        xmin, xmax = plt.xlim()
        plt.plot((shuff_025p, shuff_025p), (ymin, ymax/2), 'r-', linewidth=1)
        plt.plot(shuff_025p, ymax/2, 'ro')
        plt.plot((shuff_975p, shuff_975p), (ymin, ymax/2), 'r-', linewidth=1)
        plt.plot(shuff_975p, ymax/2, 'ro')
        plt.plot((OPerf, OPerf), (ymin, ymax), 'g--', linewidth=1)
        plt.text(shuff_025p, ymax/2-ymax/20, '2.5 percentile:\n'+'%.4f'%(shuff_025p), fontsize='x-small', ha='right', bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.35'))
        plt.text(shuff_975p, ymax/2-ymax/20, '97.5 percentile:\n'+'%.4f'%(shuff_975p), fontsize='x-small', ha='left', bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.35'))
        plt.text(OPerf, ymax-5, "Difference of Labeled Means = " + str(OPerf), fontsize='x-small', ha='center', bbox=dict(facecolor='white', edgecolor='green', boxstyle='round,pad=0.35'))
        plt.savefig(figure_path)
        plt.show(block=False)
        plt.pause(1)
        plt.close()
    return SPerf, pVal, shuffled_mean

def find_bounds_for_sig(shuffle_test_results_dict, UpBound, LowBound):
    upperbound = []
    lowerbound = []
    for frame in sorted(shuffle_test_results_dict.keys()):
        upperbound.append(np.percentile(shuffle_test_results_dict[frame]['SPerf'], UpBound))
        lowerbound.append(np.percentile(shuffle_test_results_dict[frame]['SPerf'], LowBound))
    return upperbound, lowerbound

def gen_shuffled_traces(Group1, Group2, N_Shuffles, Group1_N, Group2_N):
    # Shuffle the dataset and compare means again
    num_of_shuffles = N_Shuffles
    SPerf = np.zeros((num_of_shuffles,1))
    All_Group = np.concatenate([Group1, Group2])
    for shuff in range(num_of_shuffles):
        shuff_response = np.random.permutation(All_Group)
        SPerf[shuff] = np.nanmean(shuff_response[0:len(Group1)]) - np.nanmean(shuff_response[len(Group1):])
    # sigma
    return SPerf

def check_violations_sigBounds(shuffDiffMeansTraces, sig_upperBound, sig_lowerBound):
    outOfBounds_upper = 0
    outOfBounds_lower = 0
    for trial in shuffDiffMeansTraces:
        num_crossings_UB = 0
        num_crossings_LB = 0
        for x in range(len(trial)):
            if trial[x]>sig_upperBound[x]:
                num_crossings_UB += 1
            if trial[x]<sig_lowerBound[x]:
                num_crossings_LB += 1
        if num_crossings_UB>0:
            outOfBounds_upper += 1
        if num_crossings_LB>0:
            outOfBounds_lower += 1
    return outOfBounds_upper, outOfBounds_lower

def plot_allA_allFreq_ShuffledDiffMeans(analysis_type_str, preprocess_str, metric_str, prey_type_str, catches_dict, misses_dict, sigUB, sigLB, sigUB_corrected, sigLB_corrected, shuffDiff, firstSigFrame, TGB_bucket, baseline_len, plots_dir, todays_dt, plot_labels): 
    img_type = ['.png', '.pdf']
    ### POOL ACROSS ANIMALS ### 
    allA_C_allFreq = {}
    allA_C_N = {}
    allA_M_allFreq = {}
    allA_M_N = {}
    for animal in catches_dict.keys():
        for freq_band in catches_dict[animal].keys():
            thisA_C_N = len(catches_dict[animal][freq_band])
            if thisA_C_N != 0:
                allA_C_N[freq_band] = allA_C_N.setdefault(freq_band,0) + thisA_C_N
                for trial in catches_dict[animal][freq_band]:
                    allA_C_allFreq.setdefault(freq_band,[]).append(trial)
    for animal in misses_dict.keys():
        for freq_band in misses_dict[animal].keys():
            thisA_M_N = len(misses_dict[animal][freq_band])
            if thisA_M_N != 0:
                allA_M_N[freq_band] = allA_M_N.setdefault(freq_band,0) + thisA_M_N
                for trial in misses_dict[animal][freq_band]:
                    allA_M_allFreq.setdefault(freq_band,[]).append(trial)
    allA_C_allF_mean = {}
    allA_C_allF_std = {}
    allA_M_allF_mean = {}
    allA_M_allF_std = {}
    ObservedDiff_allF = {}
    for freq_band in allA_C_allFreq.keys():
        allA_C_allF_mean[freq_band] = np.nanmean(allA_C_allFreq[freq_band], axis=0)
        allA_C_allF_std[freq_band] = np.nanstd(allA_C_allFreq[freq_band], axis=0, ddof=1)
        allA_M_allF_mean[freq_band] = np.nanmean(allA_M_allFreq[freq_band], axis=0)
        allA_M_allF_std[freq_band] = np.nanstd(allA_M_allFreq[freq_band], axis=0, ddof=1)
        ObservedDiff_allF[freq_band] = allA_C_allF_mean[freq_band] - allA_M_allF_mean[freq_band]
    # plot each frequency band separately
    for freq_band in allA_C_allF_mean.keys():
        x_range = len(allA_C_allF_mean[freq_band])
        # set fig path and title
        figure_name = analysis_type_str +'_'+ preprocess_str +'_'+ prey_type_str + 'Trials_AllAnimals_Freq'+str(freq_band)+'_' + todays_dt + img_type[0]
        figure_path = os.path.join(plots_dir, figure_name)
        figure_title = preprocess_str + ', mean change from baseline of {m} in ROI on cuttlefish mantle during tentacle shots, as detected by {at}, Frequency Band {fb}\n Baseline: mean of {m} from t=0 to t={b} seconds \n Prey Movement type: {p}, Pooled across all animals\n Number of catches: {Nc}, Number of misses: {Nm}'.format(m=metric_str, at=analysis_type_str, fb=freq_band, b=str(baseline_len/60), p=prey_type_str, a=animal, Nc=str(allA_C_N[0]), Nm=str(allA_M_N[0]))
        # draw fig
        plt.figure(figsize=(16,16), dpi=200)
        plt.suptitle(figure_title, fontsize=12, y=0.99)
        # subplot: real data and std 
        plt.subplot(2,1,1)
        plt.title('Observed data', fontsize=10, color='grey', style='italic')
        plt.ylabel(preprocess_str+" change from baseline in power")
        plot_xticks = np.arange(0, x_range, step=60)
        plt.xticks(plot_xticks, ['%.1f'%(x/60) for x in plot_xticks])
        if freq_band == 0:
            plt.ylim(-40,30)
            label_pos_mult = 20
        elif freq_band == 1 or freq_band == 2:
            plt.ylim(-80,180)
            label_pos_mult = 90
        else: 
            plt.ylim(-150, 150)
            label_pos_mult = 85
        #plt.xlim(0,180)
        plt.xlabel("Seconds")
        plt.grid(b=True, which='major', linestyle='-')
        # set colors
        color_meanM = [0.9137, 0.470588, 0.1529, 0.8]
        color_stdM = [0.9137, 0.470588, 0.1529, 0.1]
        color_meanC = [0.58039, 0.4941, 0.7294, 0.8]
        color_stdC = [0.58039, 0.4941, 0.7294, 0.1]
        color_TGB = [0.4627, 0.1647, 0.5137, 1.0]
        color_baseline = [0.0, 0.53333, 0.215686, 1.0]
        color_pointwiseP005 = [0.2706, 0.4588, 0.70588, 1.0]
        color_globalP005 = [0.8431, 0.1882, 0.1529, 1.0]
        color_obsDiffMeans = [0.0, 0.0, 0.0, 1.0]
        color_shuffDiffMeans = [0.5686, 0.53725, 0.6, 1.0]
        color_firstSigFrame = [0.996, 0.8784, 0.5647, 1.0]
        color_firstSigFrame_fill = [0.996, 0.8784, 0.5647, 0.3]
        # plot mean of catches and misses for each frequency band
        x_frames = range(360)
        UpperBound_M = allA_M_allF_mean[freq_band] + allA_M_allF_std[freq_band]
        LowerBound_M = allA_M_allF_mean[freq_band] - allA_M_allF_std[freq_band]
        UpperBound_C = allA_C_allF_mean[freq_band] + allA_C_allF_std[freq_band]
        LowerBound_C = allA_C_allF_mean[freq_band] - allA_C_allF_std[freq_band]
        plt.plot(allA_M_allF_mean[freq_band], linewidth=2, color=color_meanM, label='Miss, Freq Band {fb}'.format(fb=freq_band))
        plt.fill_between(x_frames, UpperBound_M, LowerBound_M, color=color_stdM)
        plt.plot(allA_C_allF_mean[freq_band], linewidth=2, color=color_meanC, label='Catch, Freq Band {fb}'.format(fb=freq_band))
        plt.fill_between(x_frames, UpperBound_C, LowerBound_C, color=color_stdC)
        # label events
        ymin, ymax = plt.ylim()
        plt.plot((baseline_len, baseline_len), (ymin, ymax), linestyle='--', linewidth=2, color=color_baseline)
        plt.plot((TGB_bucket, TGB_bucket), (ymin, ymax), linestyle='--', linewidth=2, color=color_TGB)
        if plot_labels:
            plt.text(baseline_len, ymax-0.8*label_pos_mult, "End of \nbaseline period", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_baseline, boxstyle='round,pad=0.35'))
            plt.text(TGB_bucket, ymax-0.3*label_pos_mult, "Tentacles Go Ballistic\n(TGB)", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_TGB, boxstyle='round,pad=0.35'))
            plt.legend()
        #subplot: difference of observed means vs shuffled diff of means
        plt.subplot(2,1,2)
        plt.title('Significance of the Difference of means (catch vs miss), Number of shuffles = 20000', fontsize=10, color='grey', style='italic')
        plt.ylabel("Difference of "+preprocess_str+" means in "+metric_str)
        plt.xticks(plot_xticks, ['%.1f'%(x/60) for x in plot_xticks])
        if freq_band == 0:
            plt.ylim(-40,30)
            label_pos_mult = 20
        elif freq_band == 1 or freq_band == 2:
            plt.ylim(-80,190)
            label_pos_mult = 90
        else: 
            plt.ylim(-150, 150)
            label_pos_mult = 85
        #plt.xlim(0,180)
        plt.xlabel("Seconds")
        plt.grid(b=True, which='major', linestyle='-')
        # plot pointwise p<0.05
        plt.plot(sigUB[freq_band], linestyle='--', color=color_pointwiseP005, label='Pointwise p<0.05 for Freq Band '+str(freq_band))
        plt.plot(sigLB[freq_band], linestyle='--', color=color_pointwiseP005)
        # plot corrected (global) p<0.05
        plt.plot(sigUB_corrected[freq_band], linestyle='--', color=color_globalP005, label='Global p<0.05 for Freq Band '+str(freq_band))
        plt.plot(sigLB_corrected[freq_band], linestyle='--', color=color_globalP005)
        # plot shuffled diff of means
        plt.plot(shuffDiff[freq_band], linewidth=1.5, linestyle='-', color=color_shuffDiffMeans, label='Shuffled diff of means for Freq Band '+str(freq_band))
        # plot real diff of means
        plt.plot(ObservedDiff_allF[freq_band], linewidth=2, linestyle='-', color=color_obsDiffMeans, label='Observed diff of means for Freq Band '+str(freq_band))
        # plot significant frames as shaded region
        if firstSigFrame[freq_band] is not None:
            sig_x = range(firstSigFrame[freq_band], 360)
            plt.fill_between(sig_x, ObservedDiff_allF[freq_band][firstSigFrame[freq_band]:], sigUB[freq_band][firstSigFrame[freq_band]:], color=color_firstSigFrame_fill)
            plt.plot((firstSigFrame[freq_band], firstSigFrame[freq_band]), (ymin, ymax), linestyle='--', linewidth=2, color=color_firstSigFrame)
            if plot_labels:
                plt.text(firstSigFrame[freq_band], ymax-0.8*label_pos_mult, "Difference between \n catches and misses becomes \nsignificant at {s:.2f} seconds after TGB".format(s=(firstSigFrame[freq_band]/60)-3), fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_firstSigFrame, boxstyle='round,pad=0.35'))
        # label events
        ymin, ymax = plt.ylim()
        plt.plot((baseline_len, baseline_len), (ymin, ymax), linestyle='--', linewidth=2, color=color_baseline)
        plt.plot((TGB_bucket, TGB_bucket), (ymin, ymax), linestyle='--', linewidth=2, color=color_TGB)
        if plot_labels:
            plt.text(baseline_len, ymax-0.8*label_pos_mult, "End of \nbaseline period", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_baseline, boxstyle='round,pad=0.35'))
            plt.text(TGB_bucket, ymax-0.3*label_pos_mult, "Tentacles Go Ballistic\n(TGB)", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_TGB, boxstyle='round,pad=0.35'))
            plt.legend(loc='upper left')
        # save and show fig
        plt.savefig(figure_path)
        plt.show(block=False)
        plt.pause(1)
        plt.close()

def plot_allA_Canny_ShuffledDiffMeans(analysis_type_str, preprocess_str, metric_str, prey_type_str, catches_dict, misses_dict, sigUB, sigLB, sigUB_corrected, sigLB_corrected, shuffDiff, firstSigTB, TGB_bucket, baseline_len, plots_dir, todays_dt, plot_labels): 
    img_type = ['.png', '.pdf']
    ### POOL ACROSS ANIMALS ### 
    allA_C = []
    allA_C_N = 0
    allA_M = []
    allA_M_N = 0
    for animal in catches_dict:
        thisA_C_N = len(catches_dict[animal])
        if thisA_C_N != 0:
            allA_C_N = allA_C_N + thisA_C_N
            for trial in catches_dict[animal]:
                allA_C.append(trial)
    for animal in misses_dict:
        thisA_M_N = len(misses_dict[animal])
        if thisA_M_N != 0:
            allA_M_N = allA_M_N + thisA_M_N
            for trial in misses_dict[animal]:
                allA_M.append(trial)
    allA_C_mean = np.nanmean(allA_C, axis=0)
    allA_C_std = np.nanstd(allA_C, axis=0, ddof=1)
    allA_M_mean = np.nanmean(allA_M, axis=0)
    allA_M_std = np.nanstd(allA_M, axis=0, ddof=1)
    ObservedDiff = allA_C_mean - allA_M_mean
    # set fig path and title
    figure_name = analysis_type_str +'_'+ preprocess_str +'_'+ prey_type_str + 'Trials_AllAnimals_' + todays_dt + img_type[0]
    figure_path = os.path.join(plots_dir, figure_name)
    figure_title = preprocess_str + ', mean change from baseline of {m} in ROI on cuttlefish mantle during tentacle shots, as detected by {at}\n Baseline: mean of {m} from t=0 to t={b} seconds \n Prey Movement type: {p}, Pooled across all animals\n Number of catches: {Nc}, Number of misses: {Nm}'.format(m=metric_str, at=analysis_type_str, b=str(baseline_len/60), p=prey_type_str, a=animal, Nc=str(allA_C_N), Nm=str(allA_M_N))
    # draw fig
    plt.figure(figsize=(16,16), dpi=200)
    plt.suptitle(figure_title, fontsize=12, y=0.99)
    # subplot: real data and std 
    plt.subplot(2,1,1)
    plt.title('Observed data', fontsize=10, color='grey', style='italic')
    plt.ylabel(preprocess_str+" change from baseline in number of edges")
    x_range = len(allA_C_mean)
    plot_xticks = np.arange(0, x_range, step=60)
    plt.xticks(plot_xticks, ['%.1f'%(x/60) for x in plot_xticks])
    plt.ylim(-2.5,3.0)
    label_pos_mult = 1.5
    #plt.xlim(0,180)
    plt.xlabel("Seconds")
    plt.grid(b=True, which='major', linestyle='-')
    # set colors
    color_meanM = [0.9137, 0.470588, 0.1529, 0.8]
    color_stdM = [0.9137, 0.470588, 0.1529, 0.1]
    color_meanC = [0.58039, 0.4941, 0.7294, 0.8]
    color_stdC = [0.58039, 0.4941, 0.7294, 0.1]
    color_baseline = [0.0, 0.53333, 0.215686, 1.0]
    color_TGB = [0.4627, 0.1647, 0.5137, 1.0]
    color_pointwiseP005 = [0.2706, 0.4588, 0.70588, 1.0]
    color_globalP005 = [0.8431, 0.1882, 0.1529, 1.0]
    color_obsDiffMeans = [0.0, 0.0, 0.0, 1.0]
    color_shuffDiffMeans = [0.5686, 0.53725, 0.6, 1.0]
    color_firstSigFrame = [0.996, 0.8784, 0.5647, 1.0]
    color_firstSigFrame_fill = [0.996, 0.8784, 0.5647, 0.3]
    # plot mean of catches and misses
    x_tbs = range(360)
    UpperBound_M = allA_M_mean + allA_M_std
    LowerBound_M = allA_M_mean - allA_M_std
    UpperBound_C = allA_C_mean + allA_C_std
    LowerBound_C = allA_C_mean - allA_C_std
    plt.plot(allA_M_mean, linewidth=2, color=color_meanM, label='Miss')
    plt.fill_between(x_tbs, UpperBound_M, LowerBound_M, color=color_stdM)
    plt.plot(allA_C_mean, linewidth=2, color=color_meanC, label='Catch')
    plt.fill_between(x_tbs, UpperBound_C, LowerBound_C, color=color_stdC)
    # label events
    ymin, ymax = plt.ylim()
    plt.plot((baseline_len, baseline_len), (ymin, ymax), linestyle='--', linewidth=2, color=color_baseline)
    plt.plot((TGB_bucket, TGB_bucket), (ymin, ymax), linestyle='--', linewidth=2, color=color_TGB)
    if plot_labels:
        plt.text(baseline_len, ymax-0.8*label_pos_mult, "End of \nbaseline period", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_baseline, boxstyle='round,pad=0.35'))
        plt.text(TGB_bucket, ymax-0.3*label_pos_mult, "Tentacles Go Ballistic\n(TGB)", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_TGB, boxstyle='round,pad=0.35'))
        plt.legend()
    #subplot: difference of observed means vs shuffled diff of means
    plt.subplot(2,1,2)
    plt.title('Significance of the Difference of means (catch vs miss), Number of shuffles = 20000', fontsize=10, color='grey', style='italic')
    plt.ylabel("Difference of z-scored means in number of edges")
    plt.xticks(plot_xticks, ['%.1f'%(x/60) for x in plot_xticks])
    plt.ylim(-2.5,3.0)
    #plt.xlim(0,180)
    plt.xlabel("Seconds")
    plt.grid(b=True, which='major', linestyle='-')
    # plot pointwise p<0.05
    plt.plot(sigUB, linestyle='--', color=color_pointwiseP005, label='Pointwise p<0.05')
    plt.plot(sigLB, linestyle='--', color=color_pointwiseP005)
    # plot corrected (global) p<0.05
    plt.plot(sigUB_corrected, linestyle='--', color=color_globalP005, label='Global p<0.05')
    plt.plot(sigLB_corrected, linestyle='--', color=color_globalP005)
    # plot shuffled diff of means
    plt.plot(shuffDiff, linewidth=1.5, linestyle='-', color=color_shuffDiffMeans, label='Shuffled diff of means')
    # plot real diff of means
    plt.plot(ObservedDiff, linewidth=2, linestyle='-', color=color_obsDiffMeans, label='Observed diff of means')
    # plot significant time bins as shaded region
    sig_x = range(firstSigTB, 360)
    plt.fill_between(sig_x, ObservedDiff[firstSigTB:], sigUB[firstSigTB:], color=color_firstSigFrame_fill)
    # label events
    ymin, ymax = plt.ylim()
    plt.plot((baseline_len, baseline_len), (ymin, ymax), linestyle='--', linewidth=2, color=color_baseline)
    plt.plot((TGB_bucket, TGB_bucket), (ymin, ymax), linestyle='--', linewidth=2, color=color_TGB)
    plt.plot((firstSigTB, firstSigTB), (ymin, ymax), linestyle='--', linewidth=2, color=color_firstSigFrame)
    if plot_labels:
        plt.text(baseline_len, ymax-0.85*label_pos_mult, "End of \nbaseline period", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_baseline, boxstyle='round,pad=0.35'))
        plt.text(TGB_bucket, ymax-0.3*label_pos_mult, "Tentacles Go Ballistic\n(TGB)", fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_TGB, boxstyle='round,pad=0.35'))
        plt.text(firstSigTB, ymax-0.85*label_pos_mult, "Difference between \n catches and misses becomes \nsignificant at {s:.2f} seconds".format(s=firstSigTB/60), fontsize='small', ha='center', bbox=dict(facecolor='white', edgecolor=color_firstSigFrame, boxstyle='round,pad=0.35'))
        plt.legend(loc='upper left')
    # save and show fig
    plt.savefig(figure_path)
    plt.show(block=False)
    plt.pause(1)
    plt.close()

##########################################################
# BEGIN SCRIPT
##########################################################
if __name__=='__main__':
    parser = argparse.ArgumentParser(description="""Step 2 of process_cuttle_python Python Workflow.
    Loads intermediate files generated by CuttleShuttle_01_ProcessCuttlePython_genBandEnergies.py and/or by CuttleShuttle_01_CannyEdgeDetector.bonsai.
    Baselines and normalises individual trials in order to pool trials across all animals. Categorizes trials by catch versus miss.
    Makes a shuffle test of the successful versus unsuccessful tentacle shots and plots the result.""",
    epilog="""WARNING: This script takes a few hours to run shuffle tests (bootstrapped statistical test).""")
    parser.add_argument("--a", nargs='?', default="check_string_for_empty")
    parser.add_argument("--units", nargs='?', default='percent_change', help="Units of body pattern characterisation. Use 'percent_change' (default) to use granularity measure generated by CuttleShuttle_01_ProcessCuttlePython_genBandEnergies.py, or 'zscore' to use edginess measure generated by CuttleShuttle_01_CannyEdgeDetector.bonsai.")
    parser.add_argument("--baseline", nargs='?', default=60, type=int, help="Length of baseline period in timebuckets (60 timebuckets per second). Default baseline is 60 timebuckets.")
    parser.add_argument("--plotZScore", nargs='?', default=False, help="Set to 'True' to plot Z-scored individual traces when using edginess measure.")
    parser.add_argument("--plotRandomTraces", nargs='?', default=False, help="Set to 'True' to plot random traces used to correct threshold for p<0.05 in shuffle test.")
    parser.add_argument("--plotShuffles", nargs='?', default=False, help="Set to 'True' to plot histograms of shuffle tests.")
    parser.add_argument("--plotBaselineHist", nargs='?', default=False, help="Set to 'True' to plot histogram of pooled baseline values (to check distribution).")
    parser.add_argument("--plot_labels", nargs='?', default=False, help="Set to 'True' to plot event labels in final plot of shuffle test.")
    args = parser.parse_args()
    ###################################
    # SOURCE DATA AND OUTPUT FILE LOCATIONS 
    ###################################
    data_folder_percentChange, data_folder_canny, plots_folder = load_data()
    logging.info('DATA FOLDER 1: %s \n DATA FOLDER 2: %s \n PLOTS FOLDER: %s' % (data_folder_percentChange, data_folder_canny, plots_folder))
    print('DATA FOLDER 1: %s \n DATA FOLDER 2: %s \n PLOTS FOLDER: %s' % (data_folder_percentChange, data_folder_canny, plots_folder))
    ###################################
    # PLOT TOGGLES
    ###################################
    plot_zscored_data = args.plotZScore
    visualize_random_traces = args.plotRandomTraces
    plot_shuffle_tests = args.plotShuffles
    plot_baseline_hist = args.plotBaselineHist
    ###################################
    # ANALYSIS METRIC TOGGLES
    ###################################
    units = args.units
    ###################################
    # COLLECT DATA FROM DATA_FOLDER
    ###################################
    if units == 'percent_change':
        data_folder = data_folder_percentChange
        # collect all binary files with power-at-freq-band data
        all_data = glob.glob(data_folder + os.sep + "*.npy")
    if units == 'zscore':
        data_folder = data_folder_canny
        # in canny_counts_folder, list all csv files for TGB moments ("Tentacles Go Ballistic")
        all_data = glob.glob(data_folder + os.sep + "*CannyCount.csv")
    ########################################################
    ### ------ ORGANIZE DATA ------ ###
    ########################################################
    # categorize tentacle shots according to prey movement
    TGB_natural = []
    TGB_patterned = []
    TGB_causal = []
    TGB_daily = {}
    for TGB_file in all_data: 
        if units == 'percent_change':
            trial_date = os.path.basename(TGB_file).split('_')[2]
            sorted_by_session = TGB_daily.setdefault(trial_date,[]).append(TGB_file)
            trial_datetime = datetime.datetime.strptime(trial_date, '%Y-%m-%d')
            if trial_datetime < datetime.datetime(2014, 9, 13, 0, 0):
                TGB_natural.append(TGB_file)
            elif trial_datetime > datetime.datetime(2014, 10, 18, 0, 0):
                TGB_causal.append(TGB_file)
            else: 
                TGB_patterned.append(TGB_file)
        if units == 'zscore':
            csv_name = TGB_file.split(os.sep)[-1]
            trial_date = csv_name.split('_')[2]
            sorted_by_session = TGB_daily.setdefault(trial_date,[]).append(TGB_file)
            trial_datetime = datetime.datetime.strptime(trial_date, '%Y-%m-%d')
            if trial_datetime < datetime.datetime(2014, 9, 13, 0, 0):
                TGB_natural.append(TGB_file)
            elif trial_datetime > datetime.datetime(2014, 10, 18, 0, 0):
                TGB_causal.append(TGB_file)
            else: 
                TGB_patterned.append(TGB_file)
    # categorize daily sessions by animal
    all_TS_daily = {}
    all_catches_daily = {}
    all_misses_daily = {}
    for session_date in TGB_daily:
        all_TS_daily[session_date] = categorize_by_animal(TGB_daily[session_date], units)
        all_catches_daily[session_date], all_misses_daily[session_date] = categorize_by_animal_catchVmiss(TGB_daily[session_date], units)
    # collect all data and categorize by animal
    all_TS = categorize_by_animal(all_data, units)
    # collect all data and categorize by animal and type (catch vs miss)
    all_catches, all_misses = categorize_by_animal_catchVmiss(all_data, units)
    all_raw = [all_catches, all_misses]
    ########################################################
    ### ------ TIMING INFO/MOMENTS OF INTEREST ------ ###
    ########################################################
    TGB_bucket_raw = 180 # frame for moment tentacles go ballistic
    baseline_frames = args.baseline # length of baseline period in frames
    vids_total_length = 360 # length of analysed video clips in frames
    #########################################################################################
    ### ------ DATA NORMALIZATION/STANDARDIZATION: BASELINE SUBTRACTION AND ZSCORE ------ ###
    #########################################################################################
    # baseline subtraction
    if units=='zscore':
        baseline_buckets = baseline_frames
        # sav-gol filter and baseline subtract, all TS
        savgol_window = 15
        dailyTS_filtBaseSub = {}
        for session_date in all_TS_daily:
            dailyTS_filtBaseSub[session_date] = filtered_basesub_count(all_TS_daily[session_date], 'all', baseline_buckets, savgol_window)
        allTS_filtBaseSub = filtered_basesub_count(all_TS, 'all', baseline_buckets, savgol_window)
        # sav-gol filter and baseline subtract, catches versus misses
        dailyCatches_filtBaseSub = {}
        dailyMisses_filtBaseSub = {}
        for session_date in all_catches_daily:
            dailyCatches_filtBaseSub[session_date] = filtered_basesub_count(all_catches_daily[session_date], 'all', baseline_buckets, savgol_window)
        for session_date in all_misses_daily:
            dailyMisses_filtBaseSub[session_date] = filtered_basesub_count(all_misses_daily[session_date], 'all', baseline_buckets, savgol_window)
        allCatches_filtBaseSub = filtered_basesub_count(all_catches, 'all', baseline_buckets, savgol_window)
        allMisses_filtBaseSub = filtered_basesub_count(all_misses, 'all', baseline_buckets, savgol_window)
        # zscore each animal in order to pool all trials into a "superanimal"
        allTS_filtBaseSub_Zscored = zScored_count('timebin', allTS_filtBaseSub, allTS_filtBaseSub)
        allCatches_filtBaseSub_Zscored_TB = zScored_count('timebin', allCatches_filtBaseSub, allTS_filtBaseSub)
        allMisses_filtBaseSub_Zscored_TB = zScored_count('timebin', allMisses_filtBaseSub, allTS_filtBaseSub)
        allTS_filtBaseSub_Zscored_trial = zScored_count('trial', allTS_filtBaseSub, allTS_filtBaseSub)
        allCatches_filtBaseSub_Zscored_trial = zScored_count('trial', allCatches_filtBaseSub, allTS_filtBaseSub)
        allMisses_filtBaseSub_Zscored_trial = zScored_count('trial', allMisses_filtBaseSub, allTS_filtBaseSub)
        allTS_ZScored = {'ZScored_TB':allTS_filtBaseSub_Zscored, 'ZScored_trial':allTS_filtBaseSub_Zscored_trial}
        # zscore daily sessions for each animal to characterize session dynamics
        dailyTS_filtBaseSub_Zscored_trial = {}
        for session_date in dailyTS_filtBaseSub:
            dailyTS_filtBaseSub_Zscored_trial[session_date] = zScored_count('trial', dailyTS_filtBaseSub[session_date], dailyTS_filtBaseSub[session_date])
        dailyCatches_filtBaseSub_Zscored_trial = {}
        dailyMisses_filtBaseSub_Zscored_trial = {}
        for session_date in dailyCatches_filtBaseSub:
            dailyCatches_filtBaseSub_Zscored_trial[session_date] = zScored_count('trial', dailyCatches_filtBaseSub[session_date], dailyTS_filtBaseSub[session_date])
        for session_date in dailyMisses_filtBaseSub:
            dailyMisses_filtBaseSub_Zscored_trial[session_date] = zScored_count('trial', dailyMisses_filtBaseSub[session_date], dailyTS_filtBaseSub[session_date])
        preprocessed_data_to_shuffleTest = {'ZScored_TB':[allCatches_filtBaseSub_Zscored_TB,allMisses_filtBaseSub_Zscored_TB], 'ZScored_trial':[allCatches_filtBaseSub_Zscored_trial,allMisses_filtBaseSub_Zscored_trial]}
        # calculate distribution of values during baseline from all tentacle shots
        pool_of_observed_baseline_values = {}
        for zscored in allTS_ZScored:
            for animal in allTS_ZScored[zscored]:
                for trial in allTS_ZScored[zscored][animal]: 
                    this_trial_baseline = trial[:baseline_frames]
                    for value in this_trial_baseline:
                        pool_of_observed_baseline_values.setdefault(zscored,[]).append(value)
        # establish stats for baseline
        baseline_stats = {'mean': {}, 'std': {}}
        for zscored in pool_of_observed_baseline_values:
            if plot_baseline_hist:
                # sanity check the distribution of the baseline values, is it close enough to gaussian?
                plot_BaselineHistograms_perZScore('CannyEdgeDetector', zscored, 'edge counts', 'all', pool_of_observed_baseline_values, zscored, baseline_buckets, today_dateTime, plots_folder, args.plot_labels)
            mean_baseline_this_freq = np.nanmean(pool_of_observed_baseline_values[zscored])
            std_baseline_this_freq = np.nanstd(pool_of_observed_baseline_values[zscored])
            baseline_stats['mean'][zscored] = mean_baseline_this_freq
            baseline_stats['std'][zscored] = std_baseline_this_freq
        #######################################################
        ### ------------ PLOT THE ZSCORED DATA ------------ ###
        #######################################################
        if plot_zscored_data:
            ## individual animals
            plot_indiv_animals('CannyEdgeDetector', 'Zscored_TB_SavGol_BaseSub', 'edge counts', 'all', allCatches_filtBaseSub_Zscored_TB, allMisses_filtBaseSub_Zscored_TB, TGB_bucket_raw, baseline_buckets, plots_folder, today_dateTime, args.plot_labels)
            plot_indiv_animals('CannyEdgeDetector', 'Zscored_trial_SavGol_BaseSub', 'edge counts', 'all', allCatches_filtBaseSub_Zscored_trial, allMisses_filtBaseSub_Zscored_trial, TGB_bucket_raw, baseline_buckets, plots_folder, today_dateTime, args.plot_labels)
            # sanity check
            for session_date in dailyTS_filtBaseSub:
                plot_indiv_animals('CannyEdgeDetector', 'SavGol_BaseSub', 'edge counts', 'all '+session_date, dailyCatches_filtBaseSub[session_date], dailyMisses_filtBaseSub[session_date], TGB_bucket_raw, baseline_buckets, plots_folder, today_dateTime, args.plot_labels)
                plot_indiv_animals('CannyEdgeDetector', 'Zscored_trial_SavGol_Basesub', 'edge counts', 'all '+session_date, dailyCatches_filtBaseSub_Zscored_trial[session_date], dailyMisses_filtBaseSub_Zscored_trial[session_date], TGB_bucket_raw, baseline_buckets, plots_folder, today_dateTime, args.plot_labels)
    ######################################################################################
    ### ------ DATA NORMALIZATION/STANDARDIZATION: PERCENT CHANGE FROM BASELINE ------ ###
    ######################################################################################
    if units=='percent_change': 
        # convert power at frequency into percent change from baseline
        dailyTS_percentChange = {}
        for session_date in all_TS_daily:
            dailyTS_percentChange[session_date] = percent_change_from_baseline(all_TS_daily[session_date], 'all', baseline_frames)
        allTS_percentChange = percent_change_from_baseline(all_TS, 'all', baseline_frames)
        # percent change, catch vs miss
        dailyCatches_percentChange = {}
        dailyMisses_percentChange = {}
        for session_date in all_catches_daily:
            dailyCatches_percentChange[session_date] = percent_change_from_baseline(all_catches_daily[session_date], 'all', baseline_frames)
        for session_date in all_misses_daily:
            dailyMisses_percentChange[session_date] = percent_change_from_baseline(all_misses_daily[session_date], 'all', baseline_frames)
        allCatches_percentChange = percent_change_from_baseline(all_catches, 'all', baseline_frames)
        allMisses_percentChange = percent_change_from_baseline(all_misses, 'all', baseline_frames)
        preprocessed_data_to_shuffleTest = {'Percent_Change':[allCatches_percentChange, allMisses_percentChange]}
        # calculate distribution of values during baseline from all tentacle shots
        pool_of_observed_baseline_values = {}
        for animal in allTS_percentChange.keys():
            for freq_band in allTS_percentChange[animal].keys():
                for trial in allTS_percentChange[animal][freq_band]:
                    this_trial_baseline = trial[:baseline_frames]
                    for value in this_trial_baseline:
                        pool_of_observed_baseline_values.setdefault(freq_band,[]).append(value)
        # establish stats for baseline
        baseline_stats = {'mean': {}, 'std': {}}
        for freq_band in pool_of_observed_baseline_values:
            if plot_baseline_hist:
                # sanity check the distribution of the baseline values, is it close enough to gaussian?
                plot_BaselineHistograms_perFreqBand('ProcessCuttlePython', 'PercentChange', 'power at frequency', 'all', pool_of_observed_baseline_values, freq_band, baseline_frames, today_dateTime, plots_folder, args.plot_labels)
            mean_baseline_this_freq = np.nanmean(pool_of_observed_baseline_values[freq_band])
            std_baseline_this_freq = np.nanstd(pool_of_observed_baseline_values[freq_band])
            baseline_stats['mean'][freq_band] = mean_baseline_this_freq
            baseline_stats['std'][freq_band] = std_baseline_this_freq
    ########################################################
    ### -------- SHUFFLE TESTS FOR SIGNIFICANCE -------- ###
    ########################################################
    No_of_Shuffles = 20000
    logging.info('Starting Shuffle Tests, Number of Shuffles: %i' % (No_of_Shuffles))
    print('Starting Shuffle Tests, Number of Shuffles: %i' % (No_of_Shuffles))
    Shuffle_Tests = {}
    ### POOL ACROSS ALL ANIMALS, make a shuffle test for each metric
    for preprocess_type in preprocessed_data_to_shuffleTest.keys():
        logging.info('Shuffle Tests of {p} data...'.format(p=preprocess_type))
        print('Shuffle Tests of {p} data...'.format(p=preprocess_type))
        if preprocess_type == 'Percent_Change':
            allA_allFreq_catches, allA_allFreq_catches_N, allA_allFreq_misses, allA_allFreq_misses_N = pool_acrossA_keepTemporalStructure_eachFreq(preprocessed_data_to_shuffleTest[preprocess_type][0], preprocessed_data_to_shuffleTest[preprocess_type][1], 0, -1 , "all")
            allFreq_shuffleTest = {}
            for freq_band in allA_allFreq_catches.keys():
                allFreq_shuffleTest[freq_band] = {}
                for frame in range(vids_total_length):
                    allFreq_shuffleTest[freq_band][frame] = {'catch':[], 'miss':[], 'SPerf': None, 'pval': None, 'mean': None}
                    for trial in allA_allFreq_catches[freq_band]:
                        allFreq_shuffleTest[freq_band][frame]['catch'].append(trial[frame])
                    for trial in allA_allFreq_misses[freq_band]:
                        allFreq_shuffleTest[freq_band][frame]['miss'].append(trial[frame])
                    # shuffle test each frame
                    Group1String = 'AllCatches-{p}-Frame{f}-Freq{fb}'.format(p=preprocess_type, f=frame, fb=freq_band)
                    Group2String = 'AllMisses-{p}-Frame{f}-Freq{fb}'.format(p=preprocess_type, f=frame, fb=freq_band)
                    allFreq_shuffleTest[freq_band][frame]['SPerf'], allFreq_shuffleTest[freq_band][frame]['pval'], allFreq_shuffleTest[freq_band][frame]['mean'] = shuffle_test(allFreq_shuffleTest[freq_band][frame]['catch'], allFreq_shuffleTest[freq_band][frame]['miss'], No_of_Shuffles, Group1String, Group2String, allA_allFreq_catches_N, allA_allFreq_misses_N, plot_shuffle_tests, plots_folder, today_dateTime)
            Shuffle_Tests[preprocess_type] = allFreq_shuffleTest
        if 'ZScored' in preprocess_type:
            allA_Zscored_C, allA_Zscored_C_N, allA_Zscored_M, allA_Zscored_M_N = pool_acrossA_keepTemporalStructure(preprocessed_data_to_shuffleTest[preprocess_type][0], preprocessed_data_to_shuffleTest[preprocess_type][1], 0, -1 , "all")
            Zscores_shuffleTest = {}
            for timebin in range(vids_total_length):
                Zscores_shuffleTest[timebin] = {'catch':[], 'miss':[], 'SPerf': None, 'pval': None, 'mean': None}
                for trial in allA_Zscored_C:
                    Zscores_shuffleTest[timebin]['catch'].append(trial[timebin])
                for trial in allA_Zscored_M:
                    Zscores_shuffleTest[timebin]['miss'].append(trial[timebin])
                # shuffle test each time bin
                Group1String = 'AllCatches-{p}-Frame{tb}'.format(p=preprocess_type, tb=timebin)
                Group2String = 'AllMisses-{p}-Frame{tb}'.format(p=preprocess_type, tb=timebin)
                Zscores_shuffleTest[timebin]['SPerf'], Zscores_shuffleTest[timebin]['pval'], Zscores_shuffleTest[timebin]['mean'] = shuffle_test(Zscores_shuffleTest[timebin]['catch'], Zscores_shuffleTest[timebin]['miss'], No_of_Shuffles, Group1String, Group2String, allA_Zscored_C_N, allA_Zscored_M_N, plot_shuffle_tests, plots_folder, today_dateTime)
            Shuffle_Tests[preprocess_type] = Zscores_shuffleTest
        #######################################################
        ### -- CALCULATE UPPER & LOWER BOUNDS FOR P<0.05 -- ###
        #######################################################
        logging.info('Calculating upper and lower bounds for p<0.05 of {p} data...'.format(p=preprocess_type))
        print('Calculating upper and lower bounds for p<0.05 of {p} data...'.format(p=preprocess_type))
        # pointwise p<0.05 bounds
        UB_pointwise = 97.5
        LB_pointwise = 2.5
        pw005sig_UB = {}
        pw005sig_LB = {}
        for preprocess_type in Shuffle_Tests:
            if preprocess_type == 'Percent_Change':
                for freq_band in Shuffle_Tests[preprocess_type].keys():
                    pw005sig_UB[freq_band], pw005sig_LB[freq_band] = find_bounds_for_sig(Shuffle_Tests[preprocess_type][freq_band], UB_pointwise, LB_pointwise)
                # collect shuffled mean of each frame
                shuff_DiffMeans = {}
                for freq_band in Shuffle_Tests[preprocess_type].keys():
                    for frame in sorted(Shuffle_Tests[preprocess_type][freq_band].keys()):
                        shuff_DiffMeans.setdefault(freq_band,[]).append(Shuffle_Tests[preprocess_type][freq_band][frame]['mean'])
            if 'ZScored' in preprocess_type:
                pw005sig_UB[preprocess_type], pw005sig_LB[preprocess_type] = find_bounds_for_sig(Shuffle_Tests[preprocess_type], UB_pointwise, LB_pointwise)
                # collect shuffled mean of each time bin
                shuff_DiffMeans = {}
                for timebin in sorted(Shuffle_Tests[preprocess_type].keys()):
                    shuff_DiffMeans.setdefault(preprocess_type,[]).append(Shuffle_Tests[preprocess_type][timebin]['mean'])
        #######################################################
        ### -- CALCULATE REAL/OBSERVED DIFF OF MEANS -- ###
        #######################################################
        logging.info('Calculating observed difference of means of {p} data...'.format(p=preprocess_type))
        print('Calculating observed difference of means of {p} data...'.format(p=preprocess_type))
        allA_allC = {}
        allA_allM = {}
        allA_allC_mean = {}
        allA_allM_mean = {}
        Observed_DiffMeans = {}
        for preprocess_type in preprocessed_data_to_shuffleTest.keys():
            if preprocess_type == 'Percent_Change':
                for animal in preprocessed_data_to_shuffleTest[preprocess_type][0].keys():
                    for freq_band in preprocessed_data_to_shuffleTest[preprocess_type][0][animal].keys():
                        for trial in preprocessed_data_to_shuffleTest[preprocess_type][0][animal][freq_band]:
                            allA_allC.setdefault(freq_band,[]).append(trial)
                        for trial in preprocessed_data_to_shuffleTest[preprocess_type][1][animal][freq_band]:
                            allA_allM.setdefault(freq_band,[]).append(trial)
                    for freq_band in allA_allC.keys():
                        allA_allC_mean[freq_band] = np.nanmean(allA_allC[freq_band], axis=0)
                        allA_allM_mean[freq_band] = np.nanmean(allA_allM[freq_band], axis=0)
                        Observed_DiffMeans[freq_band] = allA_allC_mean[freq_band] - allA_allM_mean[freq_band]
            if 'ZScored' in preprocess_type:
                for animal in preprocessed_data_to_shuffleTest[preprocess_type][0]:
                    for trial in preprocessed_data_to_shuffleTest[preprocess_type][0][animal]:
                        allA_allC.setdefault(preprocess_type,[]).append(trial)
                    for trial in preprocessed_data_to_shuffleTest[preprocess_type][1][animal]:
                        allA_allM.setdefault(preprocess_type,[]).append(trial)
                    allA_allC_mean[preprocess_type] = np.nanmean(allA_allC[preprocess_type], axis=0)
                    allA_allM_mean[preprocess_type] = np.nanmean(allA_allM[preprocess_type], axis=0)
                    Observed_DiffMeans[preprocess_type] = allA_allC_mean[preprocess_type] - allA_allM_mean[preprocess_type]        
        ####################################################################
        ### -- GENERATE RANDOM TRACES TO CORRECT THRESHOLD FOR P<0.05 -- ###
        ####################################################################
        No_of_random_traces = 1000
        shuffledDiffMeans = {}
        shuffMeans_traces = {}
        global005sig_UB = {}
        global005sig_LB = {}
        firstCrossing_globalP005sig = {}
        firstCrossing_P005sig = {}
        for preprocess_type in Shuffle_Tests:
            logging.info('Generating random traces to correct p<0.05 threshold of {p} data, Number of random traces: {rt}'.format(p=preprocess_type, rt=No_of_random_traces))
            print('Generating random traces to correct p<0.05 threshold of {p} data, Number of random traces: {rt}'.format(p=preprocess_type, rt=No_of_random_traces))
            if preprocess_type == 'Percent_Change':
                for freq_band in Shuffle_Tests[preprocess_type].keys():
                    shuffledDiffMeans[freq_band] = {}
                    for frame in Shuffle_Tests[preprocess_type][freq_band]:
                        shuffledDiffMeans[freq_band][frame] = gen_shuffled_traces(Shuffle_Tests[preprocess_type][freq_band][frame]['catch'], Shuffle_Tests[preprocess_type][freq_band][frame]['miss'], No_of_random_traces, len(Shuffle_Tests[preprocess_type][freq_band][frame]['catch']), len(Shuffle_Tests[preprocess_type][freq_band][frame]['miss']))
                # convert to arrays for plotting
                for st in range(No_of_random_traces):
                    for freq_band in shuffledDiffMeans.keys():
                        this_trace = []
                        for frame in shuffledDiffMeans[freq_band].keys():
                            this_trace.append(shuffledDiffMeans[freq_band][frame][st][0])
                        shuffMeans_traces.setdefault(freq_band,[]).append(this_trace)
                for freq_band in shuffMeans_traces.keys():
                    shuffMeans_traces[freq_band] = np.array(shuffMeans_traces[freq_band])
                # correct the p<0.05 bounds
                UB_corrected = 99.99
                LB_corrected = 0.01
                corrected = False
                while not corrected:
                    no_violations = True
                    for freq_band in Shuffle_Tests[preprocess_type].keys():
                        global005sig_UB[freq_band], global005sig_LB[freq_band] = find_bounds_for_sig(Shuffle_Tests[preprocess_type][freq_band], UB_corrected, LB_corrected)
                        # check how many of these random traces violate the p<0.05 generated by frame-wise and trial-wise shuffle test
                        N_violations_UBcorrected, N_violations_LBcorrected = check_violations_sigBounds(shuffMeans_traces[freq_band], global005sig_UB[freq_band], global005sig_LB[freq_band])
                        if N_violations_UBcorrected>=50 or N_violations_LBcorrected>=50:
                            no_violations = False
                            break
                    if no_violations:
                        logging.info('Upper bound corrected to %f, Lower bound corrected to %f' % (UB_corrected, LB_corrected))
                        print('Upper bound corrected to %f, Lower bound corrected to %f' % (UB_corrected, LB_corrected))
                        break
                    UB_corrected += 0.001
                    LB_corrected -= 0.001
                # find where observed data crosses corrected pointwise bounds for first time just before crossing global bounds
                for freq_band in Observed_DiffMeans.keys():
                    for frame in range(len(Observed_DiffMeans[freq_band])):
                        if Observed_DiffMeans[freq_band][frame]>global005sig_UB[freq_band][frame] or Observed_DiffMeans[freq_band][frame]<global005sig_LB[freq_band][frame]:
                            firstCrossing_globalP005sig[freq_band] = frame
                            break
                    if freq_band in firstCrossing_globalP005sig.keys() and firstCrossing_globalP005sig[freq_band] != len(Observed_DiffMeans[freq_band])-1:
                        for frame in range(baseline_frames,firstCrossing_globalP005sig[freq_band]):
                            if Observed_DiffMeans[freq_band][firstCrossing_globalP005sig[freq_band]]>global005sig_UB[freq_band][firstCrossing_globalP005sig[freq_band]] and Observed_DiffMeans[freq_band][frame]>pw005sig_UB[freq_band][frame]:
                                firstCrossing_P005sig[freq_band] = frame
                                break
                            elif Observed_DiffMeans[freq_band][firstCrossing_globalP005sig[freq_band]]<global005sig_LB[freq_band][firstCrossing_globalP005sig[freq_band]] and Observed_DiffMeans[freq_band][frame]<pw005sig_LB[freq_band][frame]:
                                firstCrossing_P005sig[freq_band] = frame
                                break
                    else:
                        firstCrossing_P005sig[freq_band] = None
                # visualize
                if visualize_random_traces:
                    for freq_band in shuffMeans_traces.keys():
                        for shuff_trace in shuffMeans_traces[freq_band]:
                            plt.plot(shuff_trace, alpha=0.1)
                        plt.plot(pw005sig_UB[freq_band], 'g--')
                        plt.plot(pw005sig_LB[freq_band], 'g--')
                        plt.plot(global005sig_UB[freq_band], 'm--')
                        plt.plot(global005sig_LB[freq_band], 'm--')
                        plt.plot(shuff_DiffMeans[freq_band], 'b--')
                        plt.plot(Observed_DiffMeans[freq_band], 'k-')
                        plt.show()
            if 'ZScored' in preprocess_type:
                shuffledDiffMeans[preprocess_type] = {}
                shuffMeans_traces[preprocess_type] = []
                global005sig_UB[preprocess_type] = {}
                global005sig_LB[preprocess_type] = {}
                firstCrossing_globalP005sig[preprocess_type] = {}
                firstCrossing_P005sig[preprocess_type] = {}
                for timebin in Shuffle_Tests[preprocess_type].keys():
                    shuffledDiffMeans[preprocess_type][timebin] = gen_shuffled_traces(Shuffle_Tests[preprocess_type][timebin]['catch'], Shuffle_Tests[preprocess_type][timebin]['miss'], No_of_random_traces, len(Shuffle_Tests[preprocess_type][timebin]['catch']), len(Shuffle_Tests[preprocess_type][timebin]['miss']))
                # convert to arrays for plotting
                for st in range(No_of_random_traces):
                    this_trace = []
                    for timebin in shuffledDiffMeans[preprocess_type]:
                        this_trace.append(shuffledDiffMeans[preprocess_type][timebin][st][0])
                    shuffMeans_traces[preprocess_type].append(this_trace)
                shuffMeans_traces[preprocess_type] = np.array(shuffMeans_traces[preprocess_type])
                # correct the p<0.05 bounds
                UB_corrected = 99.99
                LB_corrected = 0.01
                corrected = False
                while not corrected:
                    no_violations = True
                    global005sig_UB[preprocess_type], global005sig_LB[preprocess_type] = find_bounds_for_sig(Shuffle_Tests[preprocess_type], UB_corrected, LB_corrected)
                    # check how many of these random traces violate the p<0.05 generated by frame-wise and trial-wise shuffle test
                    N_violations_UBcorrected, N_violations_LBcorrected = check_violations_sigBounds(shuffMeans_traces[preprocess_type], global005sig_UB[preprocess_type], global005sig_LB[preprocess_type])
                    if N_violations_UBcorrected>=50 or N_violations_LBcorrected>=50:
                        no_violations = False
                    if no_violations:
                        logging.info('Upper bound corrected to %f, Lower bound corrected to %f' % (UB_corrected, LB_corrected))
                        print('Upper bound corrected to %f, Lower bound corrected to %f' % (UB_corrected, LB_corrected))
                        break
                    UB_corrected += 0.001
                    LB_corrected -= 0.001
                # find where observed data crosses corrected pointwise bounds for first time just before crossing global bounds
                for tb in range(len(Observed_DiffMeans[preprocess_type])):
                    if Observed_DiffMeans[preprocess_type][tb]>global005sig_UB[preprocess_type][tb] or Observed_DiffMeans[preprocess_type][tb]<global005sig_LB[preprocess_type][tb]:
                        firstCrossing_globalP005sig[preprocess_type] = tb
                        break
                if firstCrossing_globalP005sig[preprocess_type] != len(Observed_DiffMeans[preprocess_type])-1:
                    for tb in range(baseline_buckets,firstCrossing_globalP005sig[preprocess_type]):
                        if Observed_DiffMeans[preprocess_type][firstCrossing_globalP005sig[preprocess_type]]>global005sig_UB[preprocess_type][firstCrossing_globalP005sig[preprocess_type]] and Observed_DiffMeans[preprocess_type][tb]>pw005sig_UB[preprocess_type][tb]:
                            firstCrossing_P005sig[preprocess_type] = tb
                            break
                        elif Observed_DiffMeans[preprocess_type][firstCrossing_globalP005sig[preprocess_type]]<global005sig_LB[preprocess_type][firstCrossing_globalP005sig[preprocess_type]] and Observed_DiffMeans[preprocess_type][tb]<pw005sig_LB[preprocess_type][tb]:
                            firstCrossing_P005sig[preprocess_type] = tb
                            break
                else:
                    firstCrossing_P005sig[preprocess_type] = None
                # visualize
                if visualize_random_traces:
                    for shuff_trace in shuffMeans_traces[preprocess_type]:
                        plt.plot(shuff_trace, alpha=0.1)
                    plt.plot(pw005sig_UB[preprocess_type], 'g--')
                    plt.plot(pw005sig_LB[preprocess_type], 'g--')
                    plt.plot(global005sig_UB[preprocess_type], 'm--')
                    plt.plot(global005sig_LB[preprocess_type], 'm--')
                    plt.plot(shuff_DiffMeans[preprocess_type], 'b--')
                    plt.plot(Observed_DiffMeans[preprocess_type], 'k-')
                    plt.show()
        #######################################################
        ### ------------ PLOT THE SHUFFLE DATA ------------ ###
        #######################################################
        for preprocess_type in Shuffle_Tests:
            logging.info('Plotting shuffle tests of {p} data...'.format(p=preprocess_type))
            print('Plotting shuffle tests of {p} data...'.format(p=preprocess_type))
            if preprocess_type == 'Percent_Change':
                for freq_band in firstCrossing_P005sig:
                    logging.info('Difference between catches and misses becomes significant at {s:.2f} seconds after TGB'.format(s=(firstCrossing_P005sig[freq_band]/60)-3))
                    print('Difference between catches and misses becomes significant at {s:.2f} seconds after TGB'.format(s=(firstCrossing_P005sig[freq_band]/60)-3))
                plot_allA_allFreq_ShuffledDiffMeans('ProcessCuttlePython', preprocess_type, 'power at frequency', 'all', preprocessed_data_to_shuffleTest[preprocess_type][0], preprocessed_data_to_shuffleTest[preprocess_type][1], pw005sig_UB, pw005sig_LB, global005sig_UB, global005sig_LB, shuff_DiffMeans, firstCrossing_P005sig, TGB_bucket_raw, baseline_frames, plots_folder, today_dateTime, args.plot_labels)
            if 'ZScored' in preprocess_type:
                logging.info('Difference between catches and misses becomes significant at {s:.2f} seconds after TGB'.format(s=(firstCrossing_P005sig[preprocess_type]/60)-3))
                print('Difference between catches and misses becomes significant at {s:.2f} seconds after TGB'.format(s=(firstCrossing_P005sig[preprocess_type]/60)-3))
                plot_allA_Canny_ShuffledDiffMeans('CannyEdgeDetector', preprocess_type, 'edge counts', 'all', preprocessed_data_to_shuffleTest[preprocess_type][0], preprocessed_data_to_shuffleTest[preprocess_type][1], pw005sig_UB[preprocess_type], pw005sig_LB[preprocess_type], global005sig_UB[preprocess_type], global005sig_LB[preprocess_type], shuff_DiffMeans[preprocess_type], firstCrossing_P005sig[preprocess_type], TGB_bucket_raw, baseline_buckets, plots_folder, today_dateTime, args.plot_labels)
# FIN